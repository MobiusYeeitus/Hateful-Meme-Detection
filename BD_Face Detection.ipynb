{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports libraries as always, many unused, why? IDFK.\n",
    "\n",
    "Correction, except pandas and cv2, everything else is unused, fuck RAM, all my homies hate RAM. -M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import glob\n",
    "import os\n",
    "import imageio\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mounting on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports pre-processed data, which is just a set of image+data, and maybe the text recognized inside the image\n",
    "\n",
    "Imports pandas again? Why? cuz fuck consistency, thats why. -M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/content/drive/MyDrive/STATS402_Project/hateful_memes/\"\n",
    "dev_seen_data= pd.read_json(path+'dev_seen.jsonl',lines=True)\n",
    "dev_unseen_data= pd.read_json(path+'dev_unseen.jsonl',lines=True)\n",
    "test_seen_data=pd.read_json(path+'test_seen.jsonl',lines=True)\n",
    "test_unseen_data=pd.read_json(path+'test_unseen.jsonl',lines=True)\n",
    "train_data=pd.read_json(path+'train.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat-ing all data again\n",
    "\n",
    "Why not drop the unnecessary columns? Save more RAM? Idiots. -M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data,test_seen_data,test_unseen_data,dev_seen_data,dev_unseen_data])\n",
    "data1 = data.drop_duplicates(subset=['img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showcase object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every image in the folder 'path', read the image, then create (yes, this creation of the face engine is in the loop, I don't see the reason why it has to recreated every single time again and again, why not just create one at the start and use it. RAM ki maa ki chuut) a face detection engine from the 'opencv-python' library, detect faces with the engine. If any faces are detected, set/reset max_area and max_coords, and output the face. Later, the face in cropped into the 'cropped' variable by using the coords extracted from the image, and resize the image into a 128x128 square image and store it into a a folder (path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/STATS402_Project/'\n",
    "path2 = '/content/drive/MyDrive/STATS402_Project/face/'\n",
    "for each in data1['img']:\n",
    "  print(each)\n",
    "  img_path = path + each\n",
    "  img = cv2.imread(img_path)\n",
    "  face_engine = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "  faces = face_engine.detectMultiScale(img,scaleFactor=1.3,minNeighbors=5)\n",
    "  if faces != ():\n",
    "    max_area = 0\n",
    "    max_cordinate = None\n",
    "    for (x,y,w,h) in faces:\n",
    "      area = h * w\n",
    "      print(area)\n",
    "      if area > max_area:\n",
    "        max_area = area\n",
    "        max_cordinate = (x,y,w,h)\n",
    "\n",
    "    cropped = img[max_cordinate[1]:max_cordinate[1]+max_cordinate[3], max_cordinate[0]:max_cordinate[0]+max_cordinate[2]]\n",
    "    pic2 = cv2.resize(cropped, (128,128), interpolation=cv2.INTER_AREA)\n",
    "    cv2.imwrite(path2 + each[4:] , pic2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this facial detection even get used in this project? IDFK."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

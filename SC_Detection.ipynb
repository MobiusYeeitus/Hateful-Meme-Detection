{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the basic imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                         #https://pandas.pydata.org/docs/index.html\n",
    "from pandas import read_csv,read_json\n",
    "\n",
    "import imageio\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input='data/img/'\n",
    "path_output='data/img_processed/'\n",
    "image_num='01243'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will try to work on text recognition in an image.\n",
    "\n",
    "Pytesseract is an optical character recognition tool for python. It is a wrapper for tor Google's Tesseract-OCR Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" * te\n",
      "When your human’ says: “%\n",
      "_ “who's agood girlas — el\n",
      "\n",
      "im o->\n",
      "4 a7\n",
      "\n",
      "} >\n",
      "—\n",
      "\n",
      "and you already know it's you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract                                          #https://pypi.org/project/pytesseract/\n",
    "\n",
    "print(pytesseract.image_to_string(path_input+image_num+'.png',lang='eng'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shit doesn't work well out of the box.\n",
    "\n",
    "It seems I will need to check out OpenCV's threshold blah blah.\n",
    "\n",
    "I'm sleepy will try tomorrow.\n",
    "\n",
    "Fuck tomorrow, today it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv                                    #https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html\n",
    "\n",
    "from cv2 import threshold,adaptiveThreshold         #threshold needs a grayscale image to work properly      \n",
    "#thresholding-> https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html\n",
    "#threshold function-> https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57\n",
    "#adaptiveThreshold function-> https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3\n",
    "\n",
    "from cv2 import cvtColor                            #changes colorspace based on the flag provided             \n",
    "#colorspace-> https://docs.opencv.org/4.x/df/d9d/tutorial_py_colorspaces.html\n",
    "#cvtColor function-> https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab\n",
    "\n",
    "from cv2 import COLOR_BGR2GRAY                      #imports the flag for BGR to Grayscale conversion\n",
    "#list of conversion flags-> \n",
    "\n",
    "from cv2 import ADAPTIVE_THRESH_MEAN_C,ADAPTIVE_THRESH_GAUSSIAN_C       #imports the flags for adaptive thresholding\n",
    "#list of adaptive threshold function flags-> https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gaa42a3e6ef26247da787bf34030ed772c\n",
    "\n",
    "from cv2 import THRESH_BINARY,THRESH_BINARY_INV     #imports the flags for types of thresholding\n",
    "#list of thresholding types flags-> https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gaa9e58d2860d4afa658ef70a9b1115576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a simple grayscale (B/W) conversion to the image with opencv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread(path_input+image_num+'.png')\n",
    "gray=cvtColor(img,COLOR_BGR2GRAY)\n",
    "\n",
    "if os.path.isdir(path_output):\n",
    "    cv.imwrite(path_output+image_num+'.png',gray)\n",
    "else:\n",
    "    os.mkdir(path_output)\n",
    "    cv.imwrite(path_output+image_num+'.png',gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the grayscale conversion, tesseract character recognition accuracy has improved (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when your humansays:\n",
      "_ ‘“who>sa good gira.\n",
      "Lh « 79\n",
      "\n",
      "and. you already Know it's you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pytesseract.image_to_string(path_output+image_num+'.png',lang='eng'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for threshold. After a lot of try and error and many voodoo dolls burned and demons summoned, it works (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_thres=adaptiveThreshold(gray,255,ADAPTIVE_THRESH_GAUSSIAN_C,THRESH_BINARY,3,9)\n",
    "cv.imwrite(path_output+image_num+'_t.png',gray_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hie Our IMA Says\n",
      "\n",
      "“who's a good oi”\n",
      "\n",
      "and sou alreaaly now i's you\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pytesseract.image_to_string(path_output+image_num+'_t.png',lang='eng'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied code from G4G gives similar output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh1 = cv.threshold(gray, 0, 255, cv.THRESH_OTSU | cv.THRESH_BINARY_INV)\n",
    "\n",
    "# Specify structure shape and kernel size. \n",
    "# Kernel size increases or decreases the area \n",
    "# of the rectangle to be detected.\n",
    "# A smaller value like (10, 10) will detect \n",
    "# each word instead of a sentence.\n",
    "rect_kernel = cv.getStructuringElement(cv.MORPH_RECT, (18, 18))\n",
    "\n",
    "# Applying dilation on the threshold image\n",
    "dilation = cv.dilate(thresh1, rect_kernel, iterations = 1)\n",
    "contours, hierarchy = cv.findContours(dilation, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Creating a copy of image\n",
    "im2 = gray_thres.copy()\n",
    "\n",
    "# A text file is created and flushed\n",
    "file = open(\"recognized.txt\", \"w+\")\n",
    "file.write(\"\")\n",
    "file.close()\n",
    "\n",
    "# Looping through the identified contours\n",
    "# Then rectangular part is cropped and passed on\n",
    "# to pytesseract for extracting text from it\n",
    "# Extracted text is then written into the text file\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv.boundingRect(cnt)\n",
    "    \n",
    "    # Drawing a rectangle on copied image\n",
    "    rect = cv.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Cropping the text block for giving input to OCR\n",
    "    cropped = im2[y:y + h, x:x + w]\n",
    "    \n",
    "    # Open the file in append mode\n",
    "    file = open(\"recognized.txt\", \"a\")\n",
    "    \n",
    "    # Apply OCR on the cropped image\n",
    "    text = pytesseract.image_to_string(cropped)\n",
    "    \n",
    "    # Appending the text into file\n",
    "    file.write(text)\n",
    "    file.write(\"\\n\")\n",
    "    \n",
    "    # Close the file\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OKAY FUCK TESSERACT, ITS SHIT, GONNA TRY KERAS OCR NEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be extra imports, will clean it up on final pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(0)                         #could be destructive later on, but hey no more screen filler\n",
    "import keras_ocr                                    #https://keras-ocr.readthedocs.io/en/latest/\n",
    "import matplotlib.pyplot as plt                     #useful for plotting bounding boxes on image to show OCR\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the pre-trained pipeline in keras-ocr\n",
    "\n",
    "You could train a fresh new one by feeding it a lot of data. Possible, but time-consuming, why do that unless you get paid for it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\Mobius\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\Mobius\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "pipe=keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list of all the local files that are to be put through the OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path='data/img/'\n",
    "indx=os.listdir(img_path)\n",
    "indx=[img_path+indx[i] for i in range(0,len(indx))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: DO NOT put the whole index in the OCR, chews through RAM, need more RAM, 8gigs in not it. Grab a slice. Even 10 images are too much it may seem. I really need more RAM.\n",
    "\n",
    "It will burn through CPU, so any background processes may/will crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 16s 16s/step\n",
      "1/1 [==============================] - 1s 973ms/step\n"
     ]
    }
   ],
   "source": [
    "test_batch=2\n",
    "images=[    keras_ocr.tools.read(url_or_path) for url_or_path in indx[:test_batch]  ]\n",
    "pred_list=pipe.recognize(images)         #initial output by the pipeline is in for format of list[image_list][string_list][tuples], you have to dig 3 deep in order to reach the string, 3 deep + 1 horizontal for the coordinates of said string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old man's way of converting the recognized texts into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' when youre feeling horny habibi asf but is periods lets try goat your on a',\n",
       " ' club meanwhile the isis strip at']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=''\n",
    "text_list=[]\n",
    "for i in range(0,test_batch):\n",
    "    for j in range(0,len(pred_list[i])):\n",
    "        text=text+' '+pred_list[i][j][0]\n",
    "    text_list.append(text)\n",
    "    text=''\n",
    "text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when</td>\n",
       "      <td>[[84.0, 6.0], [161.0, 6.0], [161.0, 37.0], [84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youre</td>\n",
       "      <td>[[161.30856, 7.490924], [249.76144, 4.889369],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feeling</td>\n",
       "      <td>[[251.18549, 4.3947678], [351.5404, 6.842449],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>horny</td>\n",
       "      <td>[[354.35297, 6.411764], [436.7614, 9.158714], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>habibi</td>\n",
       "      <td>[[161.0, 47.0], [233.0, 47.0], [233.0, 72.0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>asf</td>\n",
       "      <td>[[30.0, 48.0], [68.0, 48.0], [68.0, 73.0], [30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>but</td>\n",
       "      <td>[[68.0, 48.0], [108.0, 48.0], [108.0, 73.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>[[232.0, 48.0], [257.0, 48.0], [257.0, 72.0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>periods</td>\n",
       "      <td>[[288.52917, 48.810467], [375.8194, 46.870678]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lets</td>\n",
       "      <td>[[381.0, 48.0], [431.0, 48.0], [431.0, 73.0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>try</td>\n",
       "      <td>[[430.26233, 48.11476], [466.32788, 51.393448]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>goat</td>\n",
       "      <td>[[480.15967, 51.192024], [534.823, 48.458855],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>your</td>\n",
       "      <td>[[106.52873, 51.091354], [159.91283, 49.686516...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>on</td>\n",
       "      <td>[[256.14008, 51.24124], [287.70428, 49.26848],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a</td>\n",
       "      <td>[[464.0, 50.0], [481.0, 50.0], [481.0, 72.0], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                               bbox\n",
       "0      when  [[84.0, 6.0], [161.0, 6.0], [161.0, 37.0], [84...\n",
       "1     youre  [[161.30856, 7.490924], [249.76144, 4.889369],...\n",
       "2   feeling  [[251.18549, 4.3947678], [351.5404, 6.842449],...\n",
       "3     horny  [[354.35297, 6.411764], [436.7614, 9.158714], ...\n",
       "4    habibi  [[161.0, 47.0], [233.0, 47.0], [233.0, 72.0], ...\n",
       "5       asf  [[30.0, 48.0], [68.0, 48.0], [68.0, 73.0], [30...\n",
       "6       but  [[68.0, 48.0], [108.0, 48.0], [108.0, 73.0], [...\n",
       "7        is  [[232.0, 48.0], [257.0, 48.0], [257.0, 72.0], ...\n",
       "8   periods  [[288.52917, 48.810467], [375.8194, 46.870678]...\n",
       "9      lets  [[381.0, 48.0], [431.0, 48.0], [431.0, 73.0], ...\n",
       "10      try  [[430.26233, 48.11476], [466.32788, 51.393448]...\n",
       "11     goat  [[480.15967, 51.192024], [534.823, 48.458855],...\n",
       "12     your  [[106.52873, 51.091354], [159.91283, 49.686516...\n",
       "13       on  [[256.14008, 51.24124], [287.70428, 49.26848],...\n",
       "14        a  [[464.0, 50.0], [481.0, 50.0], [481.0, 72.0], ..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(pred_list[0],columns=('text','bbox'))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when youre feeling horny habibi asf but is periods lets try goat your on a'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ' '.join(df1['text'].tolist())\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will need to improve this later, happy this shit works and works WAYYYY BETTER\n",
    "\n",
    "Ordering is a bit wack, but eh, it will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wooimbouatamakeawooimaboutahmakenameformyselfhere"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
